{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data directory\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()),'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model directory\n",
    "\n",
    "model_dir = os.path.join(os.path.dirname(os.getcwd()), 'Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>23</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>37</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>13</td>\n",
       "      <td>3.641026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>15</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "0   ham       23  4.000000      0        0        0        4          0   \n",
       "1   ham        8  3.000000      0        0        0        0          0   \n",
       "2  spam       37  3.357143      3        1        4        5          0   \n",
       "3   ham       13  3.641026      0        0        2        2          0   \n",
       "4   ham       15  4.142857      0        0        1        5          0   \n",
       "\n",
       "   has_money  has_phone  has_url  \n",
       "0          0          0        0  \n",
       "1          0          0        0  \n",
       "2          0          1        0  \n",
       "3          0          0        0  \n",
       "4          0          0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join(data_dir, 'sms_to_ml.json'))\n",
    "df = df.sort_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing raw text\n",
    "df_raw = pd.read_csv(os.path.join(data_dir,'SMSSpamCollection.txt'), delimiter = '\\t', header = None)\n",
    "df_raw.columns = ['label', 'text']\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 1: Machine Learning model with extracted feature (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictors (X) and and label (y)\n",
    "\n",
    "X = df.loc[:, df.columns != 'label']\n",
    "y = (df.label == 'spam').values.astype(np.int)\n",
    "indices = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import options and modules\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, itrain, itest = train_test_split(X, y, indices, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best fbeta. Here, we want to punish misclassification of ham for spam 10 times as much\n",
    "\n",
    "best_beta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline which includes Scaling and Logistic Regression, Create a classifier using GridSearch for the best parameters\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression(solver = 'lbfgs'))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'lr__C':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'lr.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir, filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.954454\n",
      "Accuracy on test data:     0.953363\n",
      "AUC-ROC score     0.980943\n",
      "Fbeta score     0.949581\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_lr = training_accuracy\n",
    "te_acc_lr = test_accuracy\n",
    "auc_lr = auc\n",
    "fbeta_lr = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'lr.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline which includes Scaling and Random Forest, Create a classifier using GridSearch for the best parameters\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('rf', RandomForestClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'rf__n_estimators':[10 , 20, 30, 40, 50],\n",
    "             'rf__max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forest = RandomForestClassifier(n_estimators = 50, max_features = 'auto').fit(X,y)\n",
    "importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.bar(x = X.columns, height = importances)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'rf.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.999551\n",
      "Accuracy on test data:     0.974888\n",
      "AUC-ROC score     0.975051\n",
      "Fbeta score     0.940790\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_rf = training_accuracy\n",
    "te_acc_rf = test_accuracy\n",
    "auc_rf = auc\n",
    "fbeta_rf = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'rf.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline which includes Scaling and SVC, Create a classifier using GridSearch for the best parameters\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('svc', SVC(probability=True))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'svc__C':[0.01, 0.1, 1],\n",
    "             'svc__kernel':['linear', 'poly', 'rbf'],\n",
    "             'svc__gamma':['auto', 'scale']}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 3, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'svc.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.972627\n",
      "Accuracy on test data:     0.973094\n",
      "AUC-ROC score     0.936384\n",
      "Fbeta score     0.959767\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_svc = training_accuracy\n",
    "te_acc_svc = test_accuracy\n",
    "auc_svc = auc\n",
    "fbeta_svc = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'svc.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('scaler', StandardScaler()), ('gbc', GradientBoostingClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'gbc__n_estimators':[10, 50, 100, 200, 500],\n",
    "             'gbc__max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'gbc__learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('scaler', StandardScaler()), \n",
    "         ('gbc', GradientBoostingClassifier(learning_rate = 0.1, max_features = 'sqrt', n_estimators = 100))]\n",
    "clf = Pipeline(steps)\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'gbc.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.975993\n",
      "Accuracy on test data:     0.973991\n",
      "AUC-ROC score     0.985705\n",
      "Fbeta score     0.946712\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_gbc = training_accuracy\n",
    "te_acc_gbc = test_accuracy\n",
    "auc_gbc = auc\n",
    "fbeta_gbc = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'gbc.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of baseline algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Fbeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training_Accuracy  Test_Accuracy    AUC  Fbeta\n",
       "0  Logistic Regression              0.954          0.953  0.981  0.950\n",
       "1        Random Forest              1.000          0.975  0.975  0.941\n",
       "2                  SVC              0.973          0.973  0.936  0.960\n",
       "3                  GBC              0.976          0.974  0.986  0.947"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model':['Logistic Regression', 'Random Forest', 'SVC', 'GBC'],\n",
    "             'Training_Accuracy':[tr_acc_lr, tr_acc_rf, tr_acc_svc, tr_acc_gbc],\n",
    "             'Test_Accuracy':[te_acc_lr, te_acc_rf, te_acc_svc, te_acc_gbc],\n",
    "             'AUC':[auc_lr, auc_rf, auc_svc, auc_gbc],\n",
    "             'Fbeta':[fbeta_lr, fbeta_rf, fbeta_svc, fbeta_gbc]})\n",
    "result.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "Here we can see that GBC gave us the best result in both Test Accuracy and AUC. However, SVC gives us the best Fbeta score. We choose this algorithm to be our baseline.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'svc.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix and misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[961,   5],\n",
       "       [ 25, 124]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, clf.predict(Xtest), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "Our baseline algorithm isn't too good at the classification and we can still see a few instances where it misclassified a ham message as spam. These 5 misclassifications might mean a big deal (potentially leading to throwing out real messages!). Ideally, we don't want any of such.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_indices = np.where(ytest != clf.predict(Xtest))[0]\n",
    "misclassified = [itest[i] for i in my_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ham</td>\n",
       "      <td>13</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>spam</td>\n",
       "      <td>15</td>\n",
       "      <td>3.772727</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>16</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>21</td>\n",
       "      <td>3.851852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "263   ham       13  3.166667      1        1       10        0          0   \n",
       "598  spam       15  3.772727      3        1        1        3          0   \n",
       "731  spam       16  3.428571      1        1        0        1          0   \n",
       "751  spam       21  3.851852      1        1        0        8          0   \n",
       "856  spam       32  3.823529      1        1        1        9          0   \n",
       "\n",
       "     has_money  has_phone  has_url  \n",
       "263          0          1        0  \n",
       "598          0          0        0  \n",
       "731          0          0        0  \n",
       "751          0          0        0  \n",
       "856          0          0        0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mis = df[df.index.isin(misclassified)]\n",
    "df_mis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ham</td>\n",
       "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have an important customer service announcement. Call FREEPHONE 0800 542 0825 now!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>spam</td>\n",
       "      <td>Talk sexy!! Make new friends or fall in love in the worlds most discreet text dating service. Just text VIP to 83110 and see who you could meet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>spam</td>\n",
       "      <td>all the lastest from Stereophonics, Marley, Dizzee Racal, Libertines and The Strokes! Win Nookii games with Flirt!! Click TheMob WAP Bookmark or text WAP to 82468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear U've been invited to XCHAT. This is our final attempt to contact u! Txt CHAT to 86688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>ham</td>\n",
       "      <td>FR'NDSHIP is like a needle of a clock. Though V r in d same clock, V r nt able 2 met. Evn if V meet,itz only 4few seconds. Bt V alwys stay conected. Gud 9t;-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hello-/@drivby-:0quit edrunk sorry iff pthis makes no senrd-dnot no how ^ dancce 2 drum n basq!ihave fun 2nhite x ros xxxxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT, IMPORTANT INFORMATION FOR O2 USER. TODAY IS YOUR LUCKY DAY! 2 FIND OUT WHY LOG ONTO HTTP://WWW.URAWINNER.COM THERE IS A FANTASTIC SURPRISE AWAITING FOR YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm watching lotr w my sis dis aft. So u wan 2 meet me 4 dinner at nite a not?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have won a Nokia 7250i. This is what you get when you win our FREE auction. To take part send Nokia to 86021 now. HG/Suite342/2Lands Row/W1JHL 16+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free msg. Sorry, a service you ordered from 81303 could not be delivered as you do not have sufficient credit. Please top up to receive the service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed £1000 cash or a £2000 prize.To claim yr prize call our customer service representative on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>spam</td>\n",
       "      <td>Sppok up ur mob with a Halloween collection of nokia logo&amp;pic message plus a FREE eerie tone, txt CARD SPOOK to 8007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your next amazing xxx PICSFREE1 video will be sent to you enjoy! If one vid is not enough for 2day text back the keyword PICSFREE1 to get the next video.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>spam</td>\n",
       "      <td>Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>spam</td>\n",
       "      <td>Save money on wedding lingerie at www.bridal.petticoatdreams.co.uk Choose from a superb selection with national delivery. Brought to you by WeddingFriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>spam</td>\n",
       "      <td>Text BANNEDUK to 89555 to see! cost 150p textoperator g696ga 18+ XXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>spam</td>\n",
       "      <td>YES! The only place in town to meet exciting adult singles is now in the UK. Txt CHAT to 86688 now! 150p/Msg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>spam</td>\n",
       "      <td>Win a £1000 cash prize or a prize worth £5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>spam</td>\n",
       "      <td>Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>spam</td>\n",
       "      <td>For your chance to WIN a FREE Bluetooth Headset then simply reply back with \"ADP\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>spam</td>\n",
       "      <td>Mobile Club: Choose any of the top quality items for your mobile. 7cfca1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Motorola, Nokia etc. all FREE! Double Mins &amp; Text on Orange tariffs. TEXT YES for callback, no to remove from records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>ham</td>\n",
       "      <td>Response is one of d powerful weapon 2 occupy a place in others 'HEART'... So, always give response 2 who cares 4 U\"... Gud night..swt dreams..take care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>spam</td>\n",
       "      <td>You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "263   ham    \n",
       "598   spam   \n",
       "731   spam   \n",
       "751   spam   \n",
       "856   spam   \n",
       "907   spam   \n",
       "1073  spam   \n",
       "1086  ham    \n",
       "1235  ham    \n",
       "1407  spam   \n",
       "1477  ham    \n",
       "1536  spam   \n",
       "1699  spam   \n",
       "1874  spam   \n",
       "2402  spam   \n",
       "2480  spam   \n",
       "2575  spam   \n",
       "2663  spam   \n",
       "2770  spam   \n",
       "3443  spam   \n",
       "3562  spam   \n",
       "3758  spam   \n",
       "4047  spam   \n",
       "4295  spam   \n",
       "4410  spam   \n",
       "4506  spam   \n",
       "4578  spam   \n",
       "4861  ham    \n",
       "5037  spam   \n",
       "5120  spam   \n",
       "\n",
       "                                                                                                                                                                     text  \n",
       "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*                                                                                                                  \n",
       "598   You have an important customer service announcement. Call FREEPHONE 0800 542 0825 now!                                                                               \n",
       "731   Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123                                                                \n",
       "751   Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?                                                               \n",
       "856   Talk sexy!! Make new friends or fall in love in the worlds most discreet text dating service. Just text VIP to 83110 and see who you could meet.                     \n",
       "907   all the lastest from Stereophonics, Marley, Dizzee Racal, Libertines and The Strokes! Win Nookii games with Flirt!! Click TheMob WAP Bookmark or text WAP to 82468   \n",
       "1073  Dear U've been invited to XCHAT. This is our final attempt to contact u! Txt CHAT to 86688                                                                           \n",
       "1086  FR'NDSHIP is like a needle of a clock. Though V r in d same clock, V r nt able 2 met. Evn if V meet,itz only 4few seconds. Bt V alwys stay conected. Gud 9t;-)       \n",
       "1235  Hello-/@drivby-:0quit edrunk sorry iff pthis makes no senrd-dnot no how ^ dancce 2 drum n basq!ihave fun 2nhite x ros xxxxxxx                                        \n",
       "1407  URGENT, IMPORTANT INFORMATION FOR O2 USER. TODAY IS YOUR LUCKY DAY! 2 FIND OUT WHY LOG ONTO HTTP://WWW.URAWINNER.COM THERE IS A FANTASTIC SURPRISE AWAITING FOR YOU  \n",
       "1477  I'm watching lotr w my sis dis aft. So u wan 2 meet me 4 dinner at nite a not?                                                                                       \n",
       "1536  You have won a Nokia 7250i. This is what you get when you win our FREE auction. To take part send Nokia to 86021 now. HG/Suite342/2Lands Row/W1JHL 16+               \n",
       "1699  Free msg. Sorry, a service you ordered from 81303 could not be delivered as you do not have sufficient credit. Please top up to receive the service.                 \n",
       "1874  You have WON a guaranteed £1000 cash or a £2000 prize.To claim yr prize call our customer service representative on                                                  \n",
       "2402  Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)             \n",
       "2480  Sppok up ur mob with a Halloween collection of nokia logo&pic message plus a FREE eerie tone, txt CARD SPOOK to 8007                                                 \n",
       "2575  Your next amazing xxx PICSFREE1 video will be sent to you enjoy! If one vid is not enough for 2day text back the keyword PICSFREE1 to get the next video.            \n",
       "2663  Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?                                   \n",
       "2770  Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner                        \n",
       "3443  Save money on wedding lingerie at www.bridal.petticoatdreams.co.uk Choose from a superb selection with national delivery. Brought to you by WeddingFriend            \n",
       "3562  Text BANNEDUK to 89555 to see! cost 150p textoperator g696ga 18+ XXX                                                                                                 \n",
       "3758  YES! The only place in town to meet exciting adult singles is now in the UK. Txt CHAT to 86688 now! 150p/Msg.                                                        \n",
       "4047  Win a £1000 cash prize or a prize worth £5000                                                                                                                        \n",
       "4295  Kit Strip - you have been billed 150p. Netcollex Ltd. PO Box 1013 IG11 OJA                                                                                           \n",
       "4410  For your chance to WIN a FREE Bluetooth Headset then simply reply back with \"ADP\"                                                                                    \n",
       "4506  Mobile Club: Choose any of the top quality items for your mobile. 7cfca1a                                                                                            \n",
       "4578  Had your contract mobile 11 Mnths? Latest Motorola, Nokia etc. all FREE! Double Mins & Text on Orange tariffs. TEXT YES for callback, no to remove from records      \n",
       "4861  Response is one of d powerful weapon 2 occupy a place in others 'HEART'... So, always give response 2 who cares 4 U\"... Gud night..swt dreams..take care             \n",
       "5037  You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt                \n",
       "5120  PRIVATE! Your 2003 Account Statement for 078                                                                                                                         "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df_raw.iloc[df_mis.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "Here we can see the drawback of this approach. SMSs with clearly flaggable words like 'Txt', 'Free', the punctuation '!' were ignored as a spam signal (a few urls, phone numbers were missed because of its uniqueness). We can further code these features into our existing model to improve it, but this clearly shows the advantage of the Bag of Word model we will explore next.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Machine Learning model with Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y set\n",
    "\n",
    "X = df_raw.text\n",
    "y = (df_raw.label == 'spam').values.astype(np.int)\n",
    "indices = df_raw.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, itrain, itest = train_test_split(X, y, indices, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Bi-Gram on BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Naive Bayes\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('vec', CountVectorizer(stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')),\n",
    "         ('nb', MultinomialNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100],\n",
    "              'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'nb_bow.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.998654\n",
      "Accuracy on test data:     0.993722\n",
      "AUC-ROC score     0.983096\n",
      "Fbeta score     0.999512\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_nb_bow = training_accuracy\n",
    "te_acc_nb_bow = test_accuracy\n",
    "auc_nb_bow = auc\n",
    "fbeta_nb_bow = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'nb_bow.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Bi-Gram on TFIDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Naive Bayes and Vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('vec', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')),\n",
    "         ('nb', MultinomialNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100],\n",
    "              'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'nb_tfidf.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.999551\n",
      "Accuracy on test data:     0.989238\n",
      "AUC-ROC score     0.992226\n",
      "Fbeta score     0.972148\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_nb_tfidf = training_accuracy\n",
    "te_acc_nb_tfidf = test_accuracy\n",
    "auc_nb_tfidf = auc\n",
    "fbeta_nb_tfidf = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'nb_tfidf.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC on BOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('vec', CountVectorizer(min_df = 1, stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')),\n",
    "         ('svc', SVC(probability = True))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'svc__C':[0.01, 0.1, 1],\n",
    "             'svc__kernel':['linear', 'poly', 'rbf'],\n",
    "             'svc__gamma':['auto', 'scale']}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 3, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'svc_bow.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.998878\n",
      "Accuracy on test data:     0.982960\n",
      "AUC-ROC score     0.989405\n",
      "Fbeta score     0.991160\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_svc_bow = training_accuracy\n",
    "te_acc_svc_bow = test_accuracy\n",
    "auc_svc_bow = auc\n",
    "fbeta_svc_bow = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'svc_bow.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC on TFIDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps = [('vec', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')),\n",
    "         ('svc', SVC(probability = True))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100],\n",
    "             'svc__C':[0.01, 0.1, 1],\n",
    "             'svc__kernel':['linear', 'poly', 'rbf'],\n",
    "             'svc__gamma':['auto', 'scale']}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 3, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'svc_tfidf.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.998654\n",
      "Accuracy on test data:     0.992825\n",
      "AUC-ROC score     0.991934\n",
      "Fbeta score     0.985938\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_svc_tfidf = training_accuracy\n",
    "te_acc_svc_tfidf = test_accuracy\n",
    "auc_svc_tfidf = auc\n",
    "fbeta_svc_tfidf = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'svc_tfidf.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from bag of word models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Fbeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_BoW</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_Tfidf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC_BoW</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_Tfidf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Training_Accuracy  Test_Accuracy    AUC  Fbeta\n",
       "0  NB_BoW     0.999              0.994          0.983  1.000\n",
       "1  NB_Tfidf   1.000              0.989          0.992  0.972\n",
       "2  SVC_BoW    0.999              0.983          0.989  0.991\n",
       "3  SVC_Tfidf  1.000              0.989          0.992  0.986"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model':['NB_BoW', 'NB_Tfidf', 'SVC_BoW', 'SVC_Tfidf'],\n",
    "             'Training_Accuracy':[tr_acc_nb_bow, tr_acc_nb_tfidf, tr_acc_svc_bow, tr_acc_nb_tfidf],\n",
    "             'Test_Accuracy':[te_acc_nb_bow, te_acc_nb_tfidf, te_acc_svc_bow, te_acc_nb_tfidf],\n",
    "             'AUC':[auc_nb_bow, auc_nb_tfidf, auc_svc_bow, auc_svc_tfidf],\n",
    "             'Fbeta':[fbeta_nb_bow, fbeta_nb_tfidf, fbeta_svc_bow, fbeta_svc_tfidf]})\n",
    "result.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "We are able to get much better results by using a bag of words approach in this dataset. The test accuracy, AUC score and fbeta score increased by 1-2% point. Interestingly, using a TD-IDF vectorizer seems to increase our AUC score but reduce test accuracy and Fbeta score slightly for Naive Bayes. Otherwise, SVC and NB seems to perform very identically. It seems that if we care about Fbeta more, we should go with the simpler approach, using just a pure bag of word model. Here, we choose our Naive Bayes Bag of Word as the best model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'nb_bow.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_indices = np.where(ytest != clf.predict(Xtest))[0]\n",
    "misclassified = [itest[i] for i in my_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>spam</td>\n",
       "      <td>34</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>16</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>21</td>\n",
       "      <td>3.851852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>41</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "227   spam  34       3.650000  2      1        3        4        0           \n",
       "731   spam  16       3.428571  1      1        0        1        0           \n",
       "751   spam  21       3.851852  1      1        0        8        0           \n",
       "2402  spam  41       3.523810  1      1        3        9        0           \n",
       "2663  spam  32       2.800000  0      0        1        17       0           \n",
       "\n",
       "      has_money  has_phone  has_url  \n",
       "227   0          0          0        \n",
       "731   0          0          0        \n",
       "751   0          0          0        \n",
       "2402  0          0          0        \n",
       "2663  0          0          0        "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mis = df[df.index.isin(misclassified)]\n",
    "df_mis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>spam</td>\n",
       "      <td>Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>spam</td>\n",
       "      <td>Sorry I missed your call let's talk when you have the time. I'm on 07090201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "227   spam   \n",
       "731   spam   \n",
       "751   spam   \n",
       "2402  spam   \n",
       "2663  spam   \n",
       "3360  spam   \n",
       "3864  spam   \n",
       "\n",
       "                                                                                                                                                          text  \n",
       "227   Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES                 \n",
       "731   Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123                                                     \n",
       "751   Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?                                                    \n",
       "2402  Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)  \n",
       "2663  Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?                        \n",
       "3360  Sorry I missed your call let's talk when you have the time. I'm on 07090201529                                                                            \n",
       "3864  Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50                                                "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "df_raw.iloc[df_mis.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "Our chosen spam filter made no mistakes misclassifying ham. It's conservative nature when predicting spam cause it to misclassify quite a few spams, however. In conclusion, it seems that TFidf model performs better generally, but BoW models perform better under business assumptions. We will use the Naive Bayes Bag of Word model for our combined model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Various ensembling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model (With dense and sparse features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x39684 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizing the sparse features\n",
    "\n",
    "df_combined = df\n",
    "df_combined['text'] = df_raw['text']\n",
    "vec = CountVectorizer(min_df = 1, stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')\n",
    "vec_fit = vec.fit(df_combined.text)\n",
    "sf = vec.fit_transform(df_combined.text)\n",
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10091743, 0.0625    , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.03211009, 0.04166667, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.16513761, 0.04910714, 0.33333333, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.06422018, 0.0317029 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11926606, 0.04619565, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02752294, 0.06111111, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling dense features\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dense_feat = df.drop(['text', 'label'], axis =1)\n",
    "\n",
    "ss = MinMaxScaler()\n",
    "\n",
    "dense_feat = ss.fit_transform(dense_feat)\n",
    "dense_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21906 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the features\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "dense_feat = coo_matrix(dense_feat)\n",
    "dense_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive X and Y\n",
    "\n",
    "X = hstack([sf, dense_feat.astype(float)])\n",
    "y = (df.label == 'spam').values.astype(np.int)\n",
    "indices = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive train/test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest, itrain, itest = train_test_split(X, y, indices, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x39694 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 92282 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Multinomial Naive Bayes over the the combined dataset (with both dense and sparse features)\n",
    "\n",
    "steps = [('nb', MultinomialNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'stack_dense_sparse.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.988557\n",
      "Accuracy on test data:     0.987444\n",
      "AUC-ROC score     0.975468\n",
      "Fbeta score     0.991841\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain, ytrain)\n",
    "test_accuracy = clf.score(Xtest, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[965,   1],\n",
       "       [ 13, 136]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimps confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytest, clf.predict(Xtest), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>spam</td>\n",
       "      <td>34</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ham</td>\n",
       "      <td>13</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>16</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>21</td>\n",
       "      <td>3.851852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Talk sexy!! Make new friends or fall in love in the worlds most discreet text dating service. Just text VIP to 83110 and see who you could meet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>41</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your next amazing xxx PICSFREE1 video will be sent to you enjoy! If one vid is not enough for 2day text back the keyword PICSFREE1 to get the next video.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>spam</td>\n",
       "      <td>36</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>spam</td>\n",
       "      <td>31</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>spam</td>\n",
       "      <td>33</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey Boys. Want hot XXX pics sent direct 2 ur phone? Txt PORN to 69855, 24Hrs free and then just 50p per day. To stop text STOPBCM SF WC1N3XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>spam</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry I missed your call let's talk when you have the time. I'm on 07090201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>spam</td>\n",
       "      <td>27</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>spam</td>\n",
       "      <td>33</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "227   spam  34       3.650000  2      1        3        4        0           \n",
       "263   ham   13       3.166667  1      1        10       0        0           \n",
       "731   spam  16       3.428571  1      1        0        1        0           \n",
       "751   spam  21       3.851852  1      1        0        8        0           \n",
       "856   spam  32       3.823529  1      1        1        9        0           \n",
       "2402  spam  41       3.523810  1      1        3        9        0           \n",
       "2575  spam  32       4.166667  0      0        2        10       0           \n",
       "2663  spam  32       2.800000  0      0        1        17       0           \n",
       "2742  spam  36       3.200000  2      1        3        11       0           \n",
       "2770  spam  31       3.066667  1      1        0        9        0           \n",
       "2879  spam  33       4.000000  2      1        5        4        0           \n",
       "3360  spam  18       2.000000  1      1        2        6        0           \n",
       "3864  spam  27       2.677419  0      0        2        6        0           \n",
       "5037  spam  33       4.416667  0      0        2        9        0           \n",
       "\n",
       "      has_money  has_phone  has_url  \\\n",
       "227   0          0          0         \n",
       "263   0          1          0         \n",
       "731   0          0          0         \n",
       "751   0          0          0         \n",
       "856   0          0          0         \n",
       "2402  0          0          0         \n",
       "2575  0          0          0         \n",
       "2663  0          0          0         \n",
       "2742  0          0          0         \n",
       "2770  0          0          0         \n",
       "2879  0          0          0         \n",
       "3360  0          1          0         \n",
       "3864  1          0          0         \n",
       "5037  0          0          0         \n",
       "\n",
       "                                                                                                                                                                text  \n",
       "227   Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES                       \n",
       "263   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*                                                                                                             \n",
       "731   Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123                                                           \n",
       "751   Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?                                                          \n",
       "856   Talk sexy!! Make new friends or fall in love in the worlds most discreet text dating service. Just text VIP to 83110 and see who you could meet.                \n",
       "2402  Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)        \n",
       "2575  Your next amazing xxx PICSFREE1 video will be sent to you enjoy! If one vid is not enough for 2day text back the keyword PICSFREE1 to get the next video.       \n",
       "2663  Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?                              \n",
       "2742  I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.  \n",
       "2770  Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner                   \n",
       "2879  Hey Boys. Want hot XXX pics sent direct 2 ur phone? Txt PORN to 69855, 24Hrs free and then just 50p per day. To stop text STOPBCM SF WC1N3XX                    \n",
       "3360  Sorry I missed your call let's talk when you have the time. I'm on 07090201529                                                                                  \n",
       "3864  Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50                                                      \n",
       "5037  You won't believe it but it's true. It's Incredible Txts! Reply G now to learn truly amazing things that will blow your mind. From O2FWD only 18p/txt           "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimpes misclassifications\n",
    "\n",
    "my_indices = np.where(ytest != clf.predict(Xtest))[0]\n",
    "misclassified = [itest[i] for i in my_indices]\n",
    "df_mis = df[df.index.isin(misclassified)]\n",
    "df_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_stack_dense_sparse = training_accuracy\n",
    "te_acc_stack_dense_sparse = test_accuracy\n",
    "auc_stack_dense_sparse = auc\n",
    "fbeta_stack_dense_sparse = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'stack_dense_sparse.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Model (With dense features and proba of sparse features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y set for sparse matrix\n",
    "\n",
    "X = df_raw.text\n",
    "y = (df_raw.label == 'spam').values.astype(np.int)\n",
    "indices = df_raw.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, itrain, itest = train_test_split(X, y, indices, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='\\\\b\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'nb__alpha': [0.01, 0.1, 1, 10, 100],\n",
       "                         'vec__min_df': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit sparse features\n",
    "\n",
    "steps = [('vec', CountVectorizer(stop_words = 'english', ngram_range = (1, 2), token_pattern=r'\\b\\w+\\b')),\n",
    "         ('nb', MultinomialNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100],\n",
    "              'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 1, 'vec__min_df': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'best_vec' (GridSearchCV)\n"
     ]
    }
   ],
   "source": [
    "best_vec = clf\n",
    "%store best_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive probability of sparse matrix\n",
    "Xtrain_proba = pd.DataFrame(clf.predict_proba(Xtrain), index = itrain)\n",
    "Xtest_proba = pd.DataFrame(clf.predict_proba(Xtest), index = itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictors (X) and and label (y) for dense matrix\n",
    "df = pd.read_json(os.path.join(data_dir, 'sms_to_ml.json'))\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'label']\n",
    "y = (df.label == 'spam').values.astype(np.int)\n",
    "indices = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test set\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest, itrain, itest = train_test_split(X, y, indices, train_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_combined = pd.merge(Xtrain, Xtrain_proba, left_index=True, right_index=True)\n",
    "Xtest_combined = pd.merge(Xtest, Xtest_proba, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>23</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.540579e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>27</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.417952e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>13</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>7.412489e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>21</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.865699e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>33</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.131628e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "1978  23       4.000000  2      1        2        6        0           \n",
       "3989  27       2.833333  0      0        1        5        0           \n",
       "3935  13       3.285714  0      0        0        2        0           \n",
       "4078  21       3.785714  0      0        0        9        0           \n",
       "4086  33       3.625000  0      0        1        9        0           \n",
       "\n",
       "      has_money  has_phone  has_url             0             1  \n",
       "1978  1          0          0        1.540579e-18  1.000000e+00  \n",
       "3989  0          0          0        1.000000e+00  4.417952e-11  \n",
       "3935  0          0          0        9.999999e-01  7.412489e-08  \n",
       "4078  0          0          0        1.000000e+00  1.865699e-08  \n",
       "4086  0          0          0        8.131628e-18  1.000000e+00  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with SVC\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('svc', SVC(probability=True))]\n",
    "pipeline = Pipeline(steps)\n",
    "parameters = {'svc__C':[0.01, 0.1, 1],\n",
    "             'svc__kernel':['linear', 'poly', 'rbf'],\n",
    "             'svc__gamma':['auto', 'scale']}\n",
    "\n",
    "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\")\n",
    "clf.fit(Xtrain_combined, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "\n",
    "filename = 'stack_dense_proba.sav'\n",
    "clf = pickle.load(open(os.path.join(model_dir,filename), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.999103\n",
      "Accuracy on test data:     0.993722\n",
      "AUC-ROC score     0.996575\n",
      "Fbeta score     0.999512\n"
     ]
    }
   ],
   "source": [
    "# Derive accuracy scores\n",
    "training_accuracy = clf.score(Xtrain_combined, ytrain)\n",
    "test_accuracy = clf.score(Xtest_combined, ytest)\n",
    "\n",
    "# Derive roc_score\n",
    "probs = clf.predict_proba(Xtest_combined)[:, 1]\n",
    "auc = roc_auc_score(ytest, probs)\n",
    "\n",
    "# Derive fbeta_score\n",
    "\n",
    "fbeta = fbeta_score(ytest, clf.predict(Xtest_combined), beta = best_beta)\n",
    "\n",
    "# Print the accuracy and roc\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))\n",
    "print(\"AUC-ROC score     {:2f}\".format(auc))\n",
    "print(\"Fbeta score     {:2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[966,   0],\n",
       "       [  7, 142]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimps confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytest, clf.predict(Xtest_combined), labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_token</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>n_num</th>\n",
       "      <th>has_num</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_stops</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_money</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>spam</td>\n",
       "      <td>34</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>16</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>21</td>\n",
       "      <td>3.851852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>41</td>\n",
       "      <td>3.523810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>32</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>spam</td>\n",
       "      <td>18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry I missed your call let's talk when you have the time. I'm on 07090201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>spam</td>\n",
       "      <td>27</td>\n",
       "      <td>2.677419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  n_token  avg_wlen  n_num  has_num  n_upper  n_stops  has_email  \\\n",
       "227   spam  34       3.650000  2      1        3        4        0           \n",
       "731   spam  16       3.428571  1      1        0        1        0           \n",
       "751   spam  21       3.851852  1      1        0        8        0           \n",
       "2402  spam  41       3.523810  1      1        3        9        0           \n",
       "2663  spam  32       2.800000  0      0        1        17       0           \n",
       "3360  spam  18       2.000000  1      1        2        6        0           \n",
       "3864  spam  27       2.677419  0      0        2        6        0           \n",
       "\n",
       "      has_money  has_phone  has_url  \\\n",
       "227   0          0          0         \n",
       "731   0          0          0         \n",
       "751   0          0          0         \n",
       "2402  0          0          0         \n",
       "2663  0          0          0         \n",
       "3360  0          1          0         \n",
       "3864  1          0          0         \n",
       "\n",
       "                                                                                                                                                          text  \n",
       "227   Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES                 \n",
       "731   Email AlertFrom: Jeri StewartSize: 2KBSubject: Low-cost prescripiton drvgsTo listen to email call 123                                                     \n",
       "751   Do you realize that in about 40 years, we'll have thousands of old ladies running around with tattoos?                                                    \n",
       "2402  Babe: U want me dont u baby! Im nasty and have a thing 4 filthyguys. Fancy a rude time with a sexy bitch. How about we go slo n hard! Txt XXX SLO(4msgs)  \n",
       "2663  Hello darling how are you today? I would love to have a chat, why dont you tell me what you look like and what you are in to sexy?                        \n",
       "3360  Sorry I missed your call let's talk when you have the time. I'm on 07090201529                                                                            \n",
       "3864  Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50                                                "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimpes misclassifications\n",
    "\n",
    "my_indices = np.where(ytest != clf.predict(Xtest_combined))[0]\n",
    "misclassified = [itest[i] for i in my_indices]\n",
    "df_mis = df_combined[df_combined.index.isin(misclassified)]\n",
    "df_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the score\n",
    "\n",
    "tr_acc_stack_dense_proba = training_accuracy\n",
    "te_acc_stack_dense_proba = test_accuracy\n",
    "auc_stack_dense_proba = auc\n",
    "fbeta_stack_dense_proba = fbeta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "\n",
    "filename = 'stack_dense_proba.sav'\n",
    "pickle.dump(clf, open(os.path.join(model_dir,filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Fbeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stack_combined</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stack_proba</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Training_Accuracy  Test_Accuracy    AUC  Fbeta\n",
       "0  stack_combined  0.989              0.987          0.975  0.992\n",
       "1  stack_proba     0.999              0.994          0.997  1.000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model':['stack_combined', 'stack_proba'],\n",
    "             'Training_Accuracy':[tr_acc_stack_dense_sparse, tr_acc_stack_dense_proba],\n",
    "             'Test_Accuracy':[te_acc_stack_dense_sparse, te_acc_stack_dense_proba],\n",
    "             'AUC':[auc_stack_dense_sparse, auc_stack_dense_proba],\n",
    "             'Fbeta':[fbeta_stack_dense_sparse, fbeta_stack_dense_proba]})\n",
    "result.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "After much experimenting we were able to find our best model, which is the stack_proba model. This model is not only good in general (Accuracy score of 0.994 and AUC of 0.997) but also very strong given our business objectives (Fbeta almost 1!).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'best_model' (GridSearchCV)\n"
     ]
    }
   ],
   "source": [
    "# Save the stacked_combined model for our spam filter\n",
    "\n",
    "%store best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
